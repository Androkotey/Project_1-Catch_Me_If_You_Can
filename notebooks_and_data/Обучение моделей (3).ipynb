{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxiakB8-XqHm"
   },
   "source": [
    "В этом блокноте используются файлы, полученные при помощи предыдущих блокнотов (тренировочный и тестовый наборы данных). Наборы векторизуются, к полученным разреженным матрицам добавляются новые признаки, а затем на полученных данных обучается **логистическая регресиия** и применяется для классификации тестовых сессий.\n",
    "\n",
    "**Целевая метрика** – ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB3Sv6UmYnjN"
   },
   "source": [
    "**Содержание**\n",
    "1. Загрузка предподготовленных данных\n",
    "2. Применение CountVectorizer и TfidfVectorizer\n",
    "3. Функции для добавления фичей\n",
    "4. Применение преобразованных наборов данных для классификации\n",
    "5. Применение новых фичей для классификации\n",
    "6. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cH7eXuG9ZbKb"
   },
   "source": [
    "### Загрузка предподготовленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yp38Wzy1XcLd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import (SGDClassifier, LogisticRegression, \n",
    "                                  LogisticRegressionCV)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "PATH_TO_DATASET = os.path.join('intermediate_data', 'test_train')\n",
    "PATH_TO_DICT = os.path.join('initial_data', 'site_dict')\n",
    "\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    ''' Записывает файл для посылки в Kaggle '''\n",
    "\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MwmRRTW8Znsl"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATASET, 'train_s10_w10_m30_final.pkl'), 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATASET, 'test_s10_w10_m30_final.pkl'), 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "\n",
    "train_df = train_df.sort_values(by=['year', 'month', 'day', 'time'])\n",
    "y_train = train_df['target'].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>...</th>\n",
       "      <th>session_timespan</th>\n",
       "      <th>#unique_sites</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>08:05:57</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>08:37:23</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>08:50:13</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>08:50:17</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>08:50:20</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12224</th>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>23:33:48</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164438</th>\n",
       "      <td>4207</td>\n",
       "      <td>753.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4207.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>23:34:15</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>52</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>7330.0</td>\n",
       "      <td>3594.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>23:38:08</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156968</th>\n",
       "      <td>3328</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>3328.0</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>23:38:36</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204762</th>\n",
       "      <td>222</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>23:39:53</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253561 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        site1   site2   site3   site4   site5   site6   site7   site8   site9  \\\n",
       "21669      56    55.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "54843      56    55.0    56.0    55.0     0.0     0.0     0.0     0.0     0.0   \n",
       "77292     946   946.0   951.0   946.0   946.0   945.0   948.0   784.0   949.0   \n",
       "114021    945   948.0   949.0   948.0   945.0   946.0   947.0   945.0   946.0   \n",
       "146670    947   950.0   948.0   947.0   950.0   952.0   946.0   951.0   946.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "12224      50    50.0    48.0    49.0    48.0    52.0    52.0    49.0   303.0   \n",
       "164438   4207   753.0   753.0    52.0    50.0  4207.0  3346.0  3359.0  3346.0   \n",
       "12221      52  3346.0   784.0   784.0  3346.0   979.0  3324.0  7330.0  3594.0   \n",
       "156968   3328  3324.0  3599.0  3413.0   753.0  3328.0  3599.0  3359.0  3359.0   \n",
       "204762    222  3346.0  3346.0  3359.0    55.0  2891.0  3346.0     0.0     0.0   \n",
       "\n",
       "        site10  ...  session_timespan  #unique_sites  start_hour  day_of_week  \\\n",
       "21669      0.0  ...               0.0              8           8            5   \n",
       "54843      0.0  ...            1786.0              4           8            5   \n",
       "77292    946.0  ...               4.0              7           8            5   \n",
       "114021   946.0  ...               3.0              4           8            5   \n",
       "146670   947.0  ...               2.0              5           8            5   \n",
       "...        ...  ...               ...            ...         ...          ...   \n",
       "12224    304.0  ...              12.0              6          23            2   \n",
       "164438    38.0  ...             178.0              5          23            2   \n",
       "12221   3329.0  ...              28.0              5          23            2   \n",
       "156968  3346.0  ...              77.0              8          23            2   \n",
       "204762     0.0  ...              12.0              2          23            2   \n",
       "\n",
       "        day  month  year      time  time_of_day  target  \n",
       "21669    12      1  2013  08:05:57      morning       0  \n",
       "54843    12      1  2013  08:37:23      morning       0  \n",
       "77292    12      1  2013  08:50:13      morning       0  \n",
       "114021   12      1  2013  08:50:17      morning       0  \n",
       "146670   12      1  2013  08:50:20      morning       0  \n",
       "...     ...    ...   ...       ...          ...     ...  \n",
       "12224    30      4  2014  23:33:48      evening       0  \n",
       "164438   30      4  2014  23:34:15      evening       0  \n",
       "12221    30      4  2014  23:38:08      evening       0  \n",
       "156968   30      4  2014  23:38:36      evening       0  \n",
       "204762   30      4  2014  23:39:53      evening       0  \n",
       "\n",
       "[253561 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwVdY6kdaH_A"
   },
   "source": [
    "### Применение CountVectorizer и TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будет проведено сравнение результатов моделей, обученных на двух наборах данных полученных разными методами:\n",
    "* при помощи CountVectorizer\n",
    "* при помощи TfidfVectorizer\n",
    "\n",
    "CountVectorizer реализует простой метод bag-of-words, а TfidfVectorizer учитывает частоты вхождений сайта в сессии. Значение, полученное с использованием TfidfVectorizer рассчитывается по следующей формуле:\n",
    "\n",
    "$$TF-IDF = TF \\times IDF = \\frac{число\\:вхождений\\:слова\\:в\\:документ}{общее\\:количество\\:слов\\:в\\:документе} \\times \\log\\left( \\frac{общее\\:количество\\:документов}{число\\:документов,\\:включающих\\:слово}\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4uAPA1AybF7i"
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "\n",
    "train_df[sites].fillna(0).astype('int').to_csv(os.path.join('intermediate_data', 'train_sessions_text_cnt.txt'), \n",
    "                                               sep=' ', \n",
    "                       index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').to_csv(os.path.join('intermediate_data', 'test_sessions_text_cnt.txt'), \n",
    "                                              sep=' ', \n",
    "                       index=None, header=None)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DICT, 'site_dict.pkl'), 'rb') as file:\n",
    "    sites_dict = pickle.load(file)\n",
    "reversed_dict = {v: k for k, v in sites_dict.items()}\n",
    "reversed_dict[0] = '0'\n",
    "\n",
    "train_df[sites].fillna(0).astype('int').applymap(\n",
    "    lambda x: reversed_dict[x]).to_csv(os.path.join('intermediate_data', 'train_sessions_text_tfidf.txt'), sep=' ', \n",
    "    index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').applymap(\n",
    "    lambda x: reversed_dict[x]).to_csv(os.path.join('intermediate_data', 'test_sessions_text_tfidf.txt'), sep=' ', \n",
    "    index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBMxhFNbbfhB",
    "outputId": "54a9e470-56e9-4ba7-9070-2f7840cac1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 5), max_features=100000, tokenizer=lambda s: s.split())\n",
    "with open(os.path.join('intermediate_data', 'train_sessions_text_cnt.txt')) as inp_train_file:\n",
    "    X_train = cnt_vectorizer.fit_transform(inp_train_file)\n",
    "with open(os.path.join('intermediate_data', 'train_sessions_text_tfidf.txt')) as inp_train_file:\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(inp_train_file)\n",
    "with open(os.path.join('intermediate_data', 'test_sessions_text_cnt.txt')) as inp_test_file:\n",
    "    X_test = cnt_vectorizer.transform(inp_test_file)\n",
    "with open(os.path.join('intermediate_data', 'test_sessions_text_tfidf.txt')) as inp_test_file:\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(inp_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbZOXzX_bkW5",
    "outputId": "0e96dad7-c53a-437d-911a-c3ab6d336305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 1086',\n",
       " '10 11',\n",
       " '10 11 11',\n",
       " '10 11 12',\n",
       " '10 11 14',\n",
       " '10 11 15',\n",
       " '10 11241',\n",
       " '10 1199',\n",
       " '10 12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0 0',\n",
       " '0 0 0',\n",
       " '0 0 0 0',\n",
       " '0 0 0 0 0',\n",
       " '0.academia-assets.com',\n",
       " '0.docs.google.com',\n",
       " '0.docs.google.com 0',\n",
       " '0.docs.google.com 0 0',\n",
       " '0.docs.google.com 0 0 0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61e36ttXlzu5"
   },
   "source": [
    "### Функции для добавления фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gaGURkHimsmg"
   },
   "outputs": [],
   "source": [
    "def add_time_features(df, X_sparse):\n",
    "    ''' Добавляет индикаторы (4 признака) утра, дня, вечера и ночи '''\n",
    "\n",
    "    hour = df['start_hour']\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    night = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "    X = sp.hstack([X_sparse, morning.values.reshape(-1, 1), \n",
    "                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n",
    "                night.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7cgJguExmJBa"
   },
   "outputs": [],
   "source": [
    "def add_session_timespan(df, X_sparse):\n",
    "    ''' Добавляет продолжительность сессии в секундах (1 признак) '''\n",
    "\n",
    "    session_timespan = df['session_timespan']\n",
    "    X = sp.hstack([X_sparse, session_timespan.values.reshape(-1, 1)])\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g3peMxgamKYC"
   },
   "outputs": [],
   "source": [
    "def feature_short_session(df, X_sparse, time_min=0, time_max=3):\n",
    "    ''' Добавляет индикаторы короткой сессии (от 0 до 2 секунд) \n",
    "    (1 признак)'''\n",
    "\n",
    "    def short_session(x): \n",
    "        if ((x >= time_min) and (x < time_max)):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    times = df['session_timespan']\n",
    "    X = sp.hstack([X_sparse, times.apply(short_session).values.reshape(-1, 1)])\n",
    "    return X\n",
    "    \n",
    "\n",
    "def feature_middle_session(df, X_sparse, time_min=3, time_max=9):\n",
    "    ''' Добавляет индикаторы средней сессии (от 3 до 6 секунд) \n",
    "    (1 признак)'''\n",
    "\n",
    "    def middle_session(x): \n",
    "        if ((x >= time_min) and (x < time_max)):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    times = df['session_timespan']\n",
    "    X = sp.hstack([X_sparse, times.apply(middle_session).values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9rerr5M70bLb"
   },
   "outputs": [],
   "source": [
    "def add_top_sites(df, X_sparse, list_of_sites={3000, 2080, 27307}):\n",
    "    ''' Добавляет индикаторы (1 признак) нескольких сайтов, которые Alice \n",
    "    использует замето чаще, чем остальные люди '''\n",
    "    \n",
    "    sites = df[['site%s' % i for i in range(1, 11)]].values\n",
    "    result = [0]*sites.shape[0]\n",
    "\n",
    "    for i, session in enumerate(sites):\n",
    "        for site in session:\n",
    "            if site in list_of_sites:\n",
    "                result[i] += 1\n",
    "    \n",
    "    X = sp.hstack([X_sparse, np.array(result).reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cew_rZAF0csV"
   },
   "outputs": [],
   "source": [
    "def add_inverse_top_sites(df, X_sparse, list_of_sites={55, 56, 570, \n",
    "                                                       778, 780, 782, \n",
    "                                                       786, 812}):\n",
    "    ''' Добавляет индикаторы (1 признак) нескольких сайтов, которые Alice \n",
    "    использует замето реже, чем остальные люди '''\n",
    "\n",
    "    sites = df[['site%s' % i for i in range(1, 11)]].values\n",
    "    result = [0]*sites.shape[0]\n",
    "\n",
    "    for i, session in enumerate(sites):\n",
    "        for site in session:\n",
    "            if site in list_of_sites:\n",
    "                result[i] += 1\n",
    "    \n",
    "    X = sp.hstack([X_sparse, np.array(result).reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "umTZWHHNOiKZ"
   },
   "outputs": [],
   "source": [
    "''' Оказалось, что признак плохой и приводит к переобучению '''\n",
    "\n",
    "def add_start_hour(df, X_sparse):\n",
    "    ''' Добавляет час начала сессии (1 признак) '''\n",
    "\n",
    "    start_hour = df['start_hour']\n",
    "    X = sp.hstack([X_sparse, start_hour.values.reshape(-1, 1)])\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3sTwQvOOOuXD"
   },
   "outputs": [],
   "source": [
    "def add_day_of_week(df, X_sparse):\n",
    "    ''' Добавляет день начала сессии (1 признак) '''\n",
    "\n",
    "    day_of_week = df['day_of_week']\n",
    "    X = sp.hstack([X_sparse, day_of_week.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yewtHTuIm2f4"
   },
   "source": [
    "### Применение преобразованных наборов данных для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTXoQNpBpmlA"
   },
   "source": [
    "В данном разделе были обучены LogisticRegressionCV на двух тренировочных наборах данных:\n",
    "- К тренировочным и тестовым наборам, преобразованным при помощи CountVectorizer и TfidfVectorizer добавлены индикаторы утра, дня, вечера и ночи.\n",
    "- Определены показатели метрики roc-auc.\n",
    "- Обученные LogisticRegressionCV с найденным коэффициентом регуляризации прменены для классификации сессий в соответствующих тестовых наборах данных.\n",
    "- Отправлены посылки в соревновании на Kaggle.\n",
    "- Сделаны выводы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZrXMr7MdnCxI"
   },
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10) # для валидации\n",
    "y_train = train_df['target'].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eLaxTNKSnfyO"
   },
   "outputs": [],
   "source": [
    "X_train_cnt_1f = add_time_features(train_df.fillna(0), X_train)\n",
    "X_test_cnt_1f = add_time_features(test_df.fillna(0), X_test)\n",
    "\n",
    "X_train_tfidf_1f = add_time_features(train_df.fillna(0), X_train_tfidf)\n",
    "X_test_tfidf_1f = add_time_features(test_df.fillna(0), X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6QyvPW3pDbl",
    "outputId": "26d1f4c3-4aef-4957-8c1e-e4634bddd871"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   38.2s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.5min remaining:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Wall time: 2min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([0.1       , 0.64444444, 1.18888889, 1.73333333, 2.27777778,\n",
       "       2.82222222, 3.36666667, 3.91111111, 4.45555556, 5.        ]),\n",
       "                     cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "                     max_iter=2000, n_jobs=-1, random_state=17,\n",
       "                     scoring='roc_auc', solver='liblinear', verbose=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_c_values = np.linspace(0.1, 5, 10)\n",
    "\n",
    "logit_grid_searcher_cnt = LogisticRegressionCV(Cs=logit_c_values, \n",
    "                                            solver='liblinear', \n",
    "                                            random_state=17,\n",
    "                                            cv=time_split,\n",
    "                                            n_jobs=-1, scoring='roc_auc',\n",
    "                                            verbose=3,\n",
    "                                            max_iter=2000)\n",
    "logit_grid_searcher_cnt.fit(X_train_cnt_1f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LJq0gLFphwp",
    "outputId": "dd3b57ea-a068-4487-ce56-3b8233865164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166806003300598 0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "logit_mean_cv_scores_cnt = logit_grid_searcher_cnt.scores_[1].mean(axis=0)\n",
    "print(logit_mean_cv_scores_cnt.max(), \n",
    "      logit_grid_searcher_cnt.Cs_[logit_mean_cv_scores_cnt.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "W4dH8MpysMsF"
   },
   "outputs": [],
   "source": [
    "logit_test_pred_cnt = logit_grid_searcher_cnt.predict_proba(X_test_cnt_1f)[:, 1]\n",
    "write_to_submission_file(logit_test_pred_cnt, 'submit_cnt.csv') # 0.93980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8BHk8rNpSG2",
    "outputId": "0f24ca63-f164-430a-d78d-6155921b41d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   16.6s remaining:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   29.2s remaining:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   36.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Wall time: 39.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([0.1       , 0.64444444, 1.18888889, 1.73333333, 2.27777778,\n",
       "       2.82222222, 3.36666667, 3.91111111, 4.45555556, 5.        ]),\n",
       "                     cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "                     max_iter=2000, n_jobs=-1, random_state=17,\n",
       "                     scoring='roc_auc', solver='liblinear', verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_c_values = np.linspace(0.1, 5, 10)\n",
    "\n",
    "logit_grid_searcher_tfidf = LogisticRegressionCV(Cs=logit_c_values, \n",
    "                                            solver='liblinear', \n",
    "                                            random_state=17,\n",
    "                                            cv=time_split,\n",
    "                                            n_jobs=-1, scoring='roc_auc',\n",
    "                                            verbose=3,\n",
    "                                            max_iter=2000)\n",
    "logit_grid_searcher_tfidf.fit(X_train_tfidf_1f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbLjkRv0piSP",
    "outputId": "37aa76de-cf9c-45fb-8b83-699a2c8f2b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9245491008379615 4.455555555555556\n"
     ]
    }
   ],
   "source": [
    "logit_mean_cv_scores_tfidf = logit_grid_searcher_tfidf.scores_[1].mean(axis=0)\n",
    "print(logit_mean_cv_scores_tfidf.max(), \n",
    "      logit_grid_searcher_tfidf.Cs_[logit_mean_cv_scores_tfidf.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dhFsOGBxsNVV"
   },
   "outputs": [],
   "source": [
    "logit_test_pred_tfidf = logit_grid_searcher_tfidf.predict_proba(X_test_tfidf_1f)[:, \n",
    "1]\n",
    "write_to_submission_file(logit_test_pred_tfidf, 'submit_tfidf.csv') # 0.94368"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RTiL0v6thHe"
   },
   "source": [
    "Поскольку более высокому roc-auc в leaderboard у TfidfVectorizer соответствует более высокое значение данной метрики и на валидации, то можно сделать вывод об удачном выборе метода валидации. В дальнейшем будут использоваться наборы данных, преобразованные при помощи TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gQYrM73uuJTM"
   },
   "outputs": [],
   "source": [
    "X_train_1f = X_train_tfidf_1f\n",
    "X_test_1f = X_test_tfidf_1f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiTRMcj9utXV"
   },
   "source": [
    "### Применение новых фичей для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZOuDjZgfu1Fp"
   },
   "outputs": [],
   "source": [
    "X_train_2f = add_session_timespan(train_df, X_train_1f)\n",
    "X_test_2f = add_session_timespan(test_df, X_test_1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qtkq6xGVvXTO"
   },
   "outputs": [],
   "source": [
    "X_train_3f = feature_short_session(train_df, X_train_2f)\n",
    "X_test_3f = feature_short_session(test_df, X_test_2f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tpyV52aSvrkf"
   },
   "outputs": [],
   "source": [
    "X_train_4f = add_top_sites(train_df, X_train_3f)\n",
    "X_test_4f = add_top_sites(test_df, X_test_3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3dqEqkJLwI26"
   },
   "outputs": [],
   "source": [
    "X_train_5f = add_inverse_top_sites(train_df, X_train_4f)\n",
    "X_test_5f = add_inverse_top_sites(test_df, X_test_4f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_6f = feature_middle_session(train_df, X_train_5f)\n",
    "X_test_6f = feature_middle_session(test_df, X_test_5f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-VQ_1aZyh9w",
    "outputId": "07657228-99bd-4a0f-ca52-d1695b427e7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  4.5min remaining: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  7.0min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9321137656775317 3.6530612244897958\n"
     ]
    }
   ],
   "source": [
    "logit_c_values = np.linspace(3, 5, 50)\n",
    "\n",
    "logit_final = LogisticRegressionCV(Cs=logit_c_values, \n",
    "                                   solver='liblinear', \n",
    "                                   random_state=17,\n",
    "                                   cv=time_split,\n",
    "                                   n_jobs=-1, scoring='roc_auc',\n",
    "                                   verbose=3,\n",
    "                                   penalty='l2')\n",
    "logit_final.fit(X_train_6f, y_train)\n",
    "\n",
    "logit_mean_cv_scores = logit_final.scores_[1].mean(axis=0)\n",
    "print(logit_mean_cv_scores.max(), logit_final.Cs_[logit_mean_cv_scores.argmax()])\n",
    "\n",
    "# 0.9321137656775317 3.6530612244897958 # 0.95044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBSOY4Yb07FR",
    "outputId": "1322062e-87b5-415f-fe7d-6752cc92c215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.6530612244897958, n_jobs=-1, random_state=17,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_final = LogisticRegression(C=3.6530612244897958, \n",
    "                                 solver='liblinear', \n",
    "                                 random_state=17, \n",
    "                                 n_jobs=-1, \n",
    "                                 penalty='l2')\n",
    "logit_final.fit(X_train_6f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5TnNXApLK2j",
    "outputId": "05909c8b-e3c5-4ac2-e0db-14a29fdc5bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cv score: 0.9310553238208839\n"
     ]
    }
   ],
   "source": [
    "logit_final_cv_score = cross_val_score(logit_final, \n",
    "                                       X_train_6f, \n",
    "                                       y_train, \n",
    "                                       scoring='roc_auc', \n",
    "                                       cv=time_split).mean()\n",
    "print('final cv score:', logit_final_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_60hoNqFyx26"
   },
   "outputs": [],
   "source": [
    "logit_test_pred_final = logit_final.predict_proba(X_test_6f)[:, 1]\n",
    "write_to_submission_file(logit_test_pred_final, 'subm_logit_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score на публичной части тестовых данных: **0.95044**. Результат далёк от лучших позиций в рейтинге, однако целью проделанной работы являлось знакомство с площадкой Kaggle, получение навыков обработки и визуализации данных, а также изучение основ машинного обучения.\n",
    "\n",
    "В качестве шагов для улучшения качества построенной модели в дальнейшем будут проделаны следующие шаги:\n",
    "* применение других методов машинного обучения (бустинг над решающими деревьями, метод ближайших соседей);\n",
    "* улучшения в схеме кросс-валидации (замечено, что не всегда рост roc-auc на кросс-валидации соответствует росту roc-auc на публичной части тестовых данных);\n",
    "* проверка на переобученность модели при использовании отдельных признаков."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
